{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A) Import Niftis from Folders**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import The First Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter Folder or CSV Containing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder or CSV with files. \n",
    "import_path = r'/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/ccm_memory/results/notebook_06b/control_analyses/conjunction'\n",
    "# Ff Importing a CSV\n",
    "file_pattern = r'agreement.nii'\n",
    "# If Importing a Folder\n",
    "file_column = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.file_utils.import_functions import GiiNiiFileImport\n",
    "matrix_df1 = GiiNiiFileImport(import_path=import_path, file_column=file_column, file_pattern=file_pattern).run()\n",
    "matrix_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional: Import Additional Matrices Second Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter Information Relating to the Path of the First Set of Niftis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder or CSV with files. \n",
    "import_path = r'/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/ccm_memory/results/notebook_06b/conjunction_map-100perms'\n",
    "# Ff Importing a CSV\n",
    "file_pattern = r'conjunction.nii'\n",
    "# If Importing a Folder\n",
    "file_column = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.file_utils.import_functions import GiiNiiFileImport\n",
    "matrix_df2 = GiiNiiFileImport(import_path=import_path, file_column=file_column, file_pattern=file_pattern).run()\n",
    "matrix_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.nifti_utils.matrix_utilities import join_dataframes\n",
    "try:\n",
    "    merged_df = join_dataframes(matrix_df1, matrix_df2)\n",
    "except:\n",
    "    print('Matrix DF2 does not exist. Just using DF1')\n",
    "    merged_df = matrix_df1\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nilearn import image\n",
    "\n",
    "def apply_mask_to_dataframe(merged_df, mask_path=None):\n",
    "    \"\"\"\n",
    "    Apply a mask to a dataframe using either a provided mask or the default MNI ICBM152 mask.\n",
    "    \n",
    "    Parameters:\n",
    "    - merged_df (DataFrame): The dataframe to which the mask should be applied.\n",
    "    - mask_path (str, optional): The path to the mask image. If not provided, the MNI ICBM152 mask will be used.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: The masked dataframe containing only the rows specified by the mask.\n",
    "    \n",
    "    Example usage:\n",
    "    >>> masked_df = apply_mask_to_dataframe(merged_df, mask_path=None)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the mask data based on the provided mask_path or use default mask\n",
    "    if mask_path is not None:\n",
    "        brain_indices = np.where(image.load_img(mask_path).get_fdata().flatten() > 0)[0]\n",
    "    else:\n",
    "        from nimlab import datasets as nimds\n",
    "        mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "        mask_data = mni_mask.get_fdata().flatten()\n",
    "        brain_indices = np.where(mask_data > 0)[0]\n",
    "    \n",
    "    # Apply the mask to the dataframe\n",
    "    masked_df = merged_df.iloc[brain_indices]\n",
    "    \n",
    "    return masked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_df = apply_mask_to_dataframe(merged_df, mask_path='/Users/cu135/hires_backdrops/MNI/MNI152_T1_2mm_brain_mask.nii')\n",
    "masked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine, dice\n",
    "\n",
    "# Compute cosine similarity between the first and second columns of masked_df, only on nonzero voxels\n",
    "vec1 = masked_df.iloc[:, 0].values\n",
    "vec2 = masked_df.iloc[:, 1].values \n",
    "\n",
    "# Filter to indices where both vectors are nonzero\n",
    "nonzero_indices = (vec1 != 0) & (vec2 != 0)\n",
    "vec1_filtered = vec1[nonzero_indices]\n",
    "vec2_filtered = vec2[nonzero_indices]\n",
    "\n",
    "dice(vec1_filtered, vec2_filtered)\n",
    "\n",
    "# if len(vec1_filtered) > 0:\n",
    "#     cosine_similarity = 1 - cosine(vec1_filtered, vec2_filtered)  # Note: cosine returns distance, so subtract from 1 for similarity\n",
    "#     print(f\"Cosine similarity (on nonzero voxels): {cosine_similarity}\")\n",
    "# else:\n",
    "#     print(\"No nonzero voxels in both vectors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_df = masked_df.abs()\n",
    "# masked_df[masked_df < 3] = 0 \n",
    "# masked_df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort The Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "masked_df = masked_df.reindex(columns=natsorted(masked_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Spatial Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Correlation**\n",
    "\n",
    "method_choices:\n",
    "- 0 = pearson\n",
    "- 1 = spearman\n",
    "- 2 = kendall\n",
    "\n",
    "Only_compare_nonzero_voxels:\n",
    "- We have already removed brain-external values by masking\n",
    "- This will simply prevent comparison of voxels that are not present in both maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_choice = 1\n",
    "only_compare_nonzero_voxels=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "\n",
    "def compute_correlation(df, method_choice=0, only_compare_nonzero_voxels=False):\n",
    "    \"\"\"\n",
    "    Compute correlations among columns of a DataFrame using a specified method.\n",
    "    When only_compare_nonzero_voxels is True, only pairs of non-zero voxels are used for the computation.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (DataFrame): The dataframe for which correlations should be computed.\n",
    "    - method_choice (int, optional): An integer indicating the correlation method to be used. \n",
    "                                     0: Pearson (default), 1: Spearman, 2: Kendall.\n",
    "    - only_compare_nonzero_voxels (bool, optional): Flag to determine whether to compute correlations \n",
    "                                                    considering only non-zero voxels. Default is False.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: The correlation matrix.\n",
    "    \n",
    "    Example usage:\n",
    "    >>> corr_matrix = compute_correlation(df, method_choice=0, only_compare_nonzero_voxels=True)\n",
    "    \"\"\"\n",
    "    \n",
    "    methods = ['pearson', 'spearman', 'kendall']\n",
    "    method = methods[method_choice]\n",
    "    \n",
    "    # If only_compare_nonzero_voxels is False, compute the correlation in the usual manner\n",
    "    if not only_compare_nonzero_voxels:\n",
    "        return df.corr(method=method), method\n",
    "    else:\n",
    "        columns = df.columns\n",
    "        n = len(columns)\n",
    "        \n",
    "        # Initialize a dataframe to store the results\n",
    "        corr_df = pd.DataFrame(index=columns, columns=columns, dtype='float64')\n",
    "        \n",
    "        # Iterate over each pair of columns\n",
    "        for i in tqdm(range(n)):\n",
    "            for j in range(i, n):\n",
    "                # Filter rows where both columns have non-zero values\n",
    "                temp_df = df[(df[columns[i]] != 0) & (df[columns[j]] != 0)]\n",
    "                \n",
    "                # Compute correlation for the filtered rows\n",
    "                corr_value = temp_df[[columns[i], columns[j]]].corr(method=method).iloc[0, 1]\n",
    "                \n",
    "                # Assign the computed value to the result dataframe\n",
    "                corr_df.iloc[i, j] = corr_value\n",
    "                corr_df.iloc[j, i] = corr_value\n",
    "                \n",
    "    #Sort the Dataframe            \n",
    "    corr_df = corr_df.reindex(index=natsorted(corr_df.index))\n",
    "    corr_df = corr_df.reindex(columns=natsorted(corr_df.columns))\n",
    "    return corr_df, method\n",
    "\n",
    "import os\n",
    "\n",
    "def save_correlation_results(corr_df, fig, out_dir, save=False, method_choice=0):\n",
    "    \"\"\"\n",
    "    Save the correlation dataframe and figure to specified output directory.\n",
    "    \n",
    "    Parameters:\n",
    "    - out_dir (str): The base directory where the results should be saved.\n",
    "    - comparison (str): The specific comparison or sub-directory under out_dir.\n",
    "    - save (bool, optional): Flag to determine whether to save results. Default is False.\n",
    "    - method_choice (int, optional): An integer indicating the correlation method used. \n",
    "                                     0: Pearson (default), 1: Spearman, 2: Kendall.\n",
    "    \n",
    "    Example usage:\n",
    "    >>> save_correlation_results('/path/to/output', 'specific_comparison', save=True, method_choice=1)\n",
    "    \"\"\"\n",
    "    methods = ['spatial_pearson', 'spatial_spearman', 'spatial_kendall']\n",
    "    method_choice = methods[method_choice]\n",
    "    if save:\n",
    "        out_dir = os.path.join(out_dir, 'spatial_correlation')\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        corr_df.to_csv(os.path.join(out_dir, f'{method_choice}_correlation_df.csv'))\n",
    "        fig.savefig(os.path.join(out_dir, f'{method_choice}_correlation_matrix.png'))\n",
    "        print('saved to ' + os.path.join(out_dir, f'{method_choice}_correlation_matrix.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df, method = compute_correlation(masked_df, method_choice=method_choice, \n",
    "                                      only_compare_nonzero_voxels=only_compare_nonzero_voxels)\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the Correlation Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create heatmap of correlation matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(15, 13))\n",
    "sns.heatmap(corr_df, cmap='ocean_hot',square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, vmin=-1, vmax=1)       \n",
    "save_correlation_results(corr_df=corr_df, fig=fig, out_dir=out_dir, save=True, method_choice=method_choice)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show Specific Heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter networks of interest\n",
    "network_of_interest = '150_vat_seed_compound_fMRI_efield_func_seed_T.nii'\n",
    "networks_of_disinterest = [\n",
    "    None   \n",
    "]\n",
    "\n",
    "#---isolate network of interest and remove those not of interest\n",
    "corr_df_2 = corr_df.copy()\n",
    "corr_df_2 = pd.DataFrame(corr_df_2.loc[:, network_of_interest])\n",
    "if networks_of_disinterest[0] is not None:\n",
    "    for network in networks_of_disinterest:\n",
    "        corr_df_2.drop(network, inplace=True)\n",
    "#Sort the dataframe by descending order\n",
    "corr_df_2 = corr_df_2.sort_values(network_of_interest)\n",
    "#Remove .nii from file names\n",
    "for name in corr_df_2.columns.values:\n",
    "    newname = name.split('.nii')[0]\n",
    "    corr_df_2 = corr_df_2.rename({name: newname}, axis='columns')\n",
    "for name in corr_df_2.index.values:\n",
    "    newname = name.split('.nii')[0]\n",
    "    corr_df_2 = corr_df_2.rename({name: newname}, axis='index')\n",
    "\n",
    "#---Visualize the new data\n",
    "#Create heatmap of correlation matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(15, 13))\n",
    "\n",
    "sns.heatmap(corr_df_2, cmap='ocean_hot',square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, vmin=-1, vmax=1)\n",
    "\n",
    "#Save results\n",
    "fig.savefig(out_dir + f'/spcorrel_{network_of_interest}.png')\n",
    "fig.savefig(out_dir + f'/spcorrel_{network_of_interest}.svg')\n",
    "corr_df_2.to_csv(out_dir + f'/spcorrel_{network_of_interest}.csv')\n",
    "display(corr_df_2)\n",
    "print(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract the Cross-Correlation Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cross_correlation_diagonal(corr_df):\n",
    "    \"\"\"\n",
    "    Extracts the diagonal of the cross-correlation from the given correlation matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - corr_df (DataFrame): The correlation matrix.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: The diagonal of the cross-correlation with the patient identifiers as the index.\n",
    "    \n",
    "    Example usage:\n",
    "    >>> cross_corr_diag = extract_cross_correlation_diagonal(corr_df)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Assuming the dataframe is square and has an even number of columns,\n",
    "    # split it into two equal parts\n",
    "    n = len(corr_df)\n",
    "    half_n = n // 2\n",
    "    \n",
    "    # Extract the values from the intersection of the rows of the first dataset \n",
    "    # and the columns of the second dataset\n",
    "    cross_corr_values = [corr_df.iloc[i, i + half_n] for i in range(half_n)]\n",
    "    \n",
    "    # Convert to DataFrame while maintaining the index from the original corr_df\n",
    "    cross_corr_df = pd.DataFrame(cross_corr_values, index=corr_df.index[:half_n], columns=[\"Cross-Correlation\"])\n",
    "    \n",
    "    return cross_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_corr_diagonal_df = extract_cross_correlation_diagonal(corr_df)\n",
    "cross_corr_diagonal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create heatmap of correlation matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(15, 13))\n",
    "sns.heatmap(cross_corr_diagonal_df, cmap='ocean_hot',square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, vmin=-1, vmax=1)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_cross_correlation_results(corr_df, fig, out_dir, comparison, save=False, method_choice=0):\n",
    "    \"\"\"\n",
    "    Save the correlation dataframe and figure to specified output directory.\n",
    "    \n",
    "    Parameters:\n",
    "    - out_dir (str): The base directory where the results should be saved.\n",
    "    - comparison (str): The specific comparison or sub-directory under out_dir.\n",
    "    - save (bool, optional): Flag to determine whether to save results. Default is False.\n",
    "    - method_choice (int, optional): An integer indicating the correlation method used. \n",
    "                                     0: Pearson (default), 1: Spearman, 2: Kendall.\n",
    "    \n",
    "    Example usage:\n",
    "    >>> save_correlation_results('/path/to/output', 'specific_comparison', save=True, method_choice=1)\n",
    "    \"\"\"\n",
    "    \n",
    "    if save:\n",
    "        out_dir = os.path.join(out_dir, comparison)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        corr_df.to_csv(os.path.join(out_dir, f'{method_choice}_cross_correlation_df.csv'))\n",
    "        fig.savefig(os.path.join(out_dir, f'{method_choice}_cross_correlation_matrix.png'))\n",
    "        print('saved to ' + os.path.join(out_dir, f'{method_choice}_cross_correlation_matrix.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cross_correlation_results(corr_df=cross_corr_diagonal_df, fig=fig, out_dir=out_dir, comparison=comparison, save=save_results, method_choice=method_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Permute Spatial Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "\n",
    "class PermutedSpatialCorrelation:\n",
    "    def __init__(self, dataframe, n_permutations=1000):\n",
    "        self.dataframe = dataframe\n",
    "        self.n_permutations = n_permutations\n",
    "        self.permuted_correlations = []\n",
    "        self.observed_correlation = None\n",
    "\n",
    "    def compute_correlation(self, df, method_choice=0, only_compare_nonzero_voxels=False):\n",
    "        \"\"\"\n",
    "        Compute correlations among columns of a DataFrame using a specified method.\n",
    "        When only_compare_nonzero_voxels is True, only pairs of non-zero voxels are used for the computation.\n",
    "        \n",
    "        Parameters:\n",
    "        - df (DataFrame): The dataframe for which correlations should be computed.\n",
    "        - method_choice (int, optional): An integer indicating the correlation method to be used. \n",
    "                                        0: Pearson (default), 1: Spearman, 2: Kendall.\n",
    "        - only_compare_nonzero_voxels (bool, optional): Flag to determine whether to compute correlations \n",
    "                                                        considering only non-zero voxels. Default is False.\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame: The correlation matrix.\n",
    "        \n",
    "        Example usage:\n",
    "        >>> corr_matrix = compute_correlation(df, method_choice=0, only_compare_nonzero_voxels=True)\n",
    "        \"\"\"\n",
    "        \n",
    "        methods = ['pearson', 'spearman', 'kendall']\n",
    "        method = methods[method_choice]\n",
    "        \n",
    "        # If only_compare_nonzero_voxels is False, compute the correlation in the usual manner\n",
    "        if not only_compare_nonzero_voxels:\n",
    "            return df.corr(method=method), method\n",
    "        else:\n",
    "            columns = df.columns\n",
    "            n = len(columns)\n",
    "            \n",
    "            # Initialize a dataframe to store the results\n",
    "            corr_df = pd.DataFrame(index=columns, columns=columns, dtype='float64')\n",
    "            \n",
    "            # Iterate over each pair of columns\n",
    "            for i in tqdm(range(n)):\n",
    "                for j in range(i, n):\n",
    "                    # Filter rows where both columns have non-zero values\n",
    "                    temp_df = df[(df[columns[i]] != 0) & (df[columns[j]] != 0)]\n",
    "                    \n",
    "                    # Compute correlation for the filtered rows\n",
    "                    corr_value = temp_df[[columns[i], columns[j]]].corr(method=method).iloc[0, 1]\n",
    "                    \n",
    "                    # Assign the computed value to the result dataframe\n",
    "                    corr_df.iloc[i, j] = corr_value\n",
    "                    corr_df.iloc[j, i] = corr_value\n",
    "                    \n",
    "        #Sort the Dataframe            \n",
    "        corr_df = corr_df.reindex(index=natsorted(corr_df.index))\n",
    "        corr_df = corr_df.reindex(columns=natsorted(corr_df.columns))\n",
    "        return corr_df, method\n",
    "\n",
    "\n",
    "    def permute_column(self, column):\n",
    "        return np.random.permutation(column)\n",
    "\n",
    "    def permute_and_correlate(self):\n",
    "        permuted_df = self.dataframe.copy()\n",
    "        for col in permuted_df.columns:\n",
    "            permuted_df[col] = self.permute_column(permuted_df[col])\n",
    "        permuted_corr, _ = self.compute_correlation(permuted_df)\n",
    "        return permuted_corr\n",
    "\n",
    "    def run_permutations(self):\n",
    "        self.observed_correlation, _ = self.compute_correlation(self.dataframe)\n",
    "        for _ in tqdm(range(self.n_permutations)):\n",
    "            permuted_corr = self.permute_and_correlate()\n",
    "            self.permuted_correlations.append(permuted_corr)\n",
    "\n",
    "    def compute_p_value(self):\n",
    "        if self.observed_correlation is None:\n",
    "            raise ValueError(\"Run permutations first to compute observed correlation.\")\n",
    "        p_values = pd.DataFrame(index=self.dataframe.columns, columns=self.dataframe.columns)\n",
    "        for i, col_i in enumerate(self.dataframe.columns):\n",
    "            for j, col_j in enumerate(self.dataframe.columns):\n",
    "                bool_array = [permuted_corr.iloc[i, j] > self.observed_correlation.iloc[i, j]\n",
    "                              for permuted_corr in self.permuted_correlations]\n",
    "                p_values.iloc[i, j] = np.mean(bool_array)\n",
    "        return p_values\n",
    "\n",
    "    def run(self):\n",
    "        self.run_permutations()\n",
    "        p_values = self.compute_p_value()\n",
    "        return p_values, self.observed_correlation\n",
    "\n",
    "# Usage:\n",
    "# Create an instance of the class\n",
    "# psc = PermutedSpatialCorrelation(dataframe, n_permutations=1000)\n",
    "# p_values, observed_corr = psc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psc = PermutedSpatialCorrelation(masked_df, n_permutations=10000)\n",
    "p_values, observed_corr = psc.run()\n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_agreement(df, method_choice='dice'):\n",
    "    \"\"\"\n",
    "    Compute agreement among columns of a DataFrame using a specified method.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (DataFrame): The dataframe for which agreement should be computed.\n",
    "    - method_choice (str, optional): A string indicating the agreement method to be used. \n",
    "                                     'dice': Dice Coefficient, 'jaccard': Jaccard Index, 'percent': % Agreement\n",
    "    \n",
    "    Returns:\n",
    "    - Tuple(DataFrame, DataFrame, DataFrame): Positive agreement matrix, Negative agreement matrix, Overall agreement matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    columns = df.columns\n",
    "    n = len(columns)\n",
    "    \n",
    "    # Initialize dataframes to store the results\n",
    "    pos_corr_df = pd.DataFrame(index=columns, columns=columns, dtype='float64') if method_choice != 'percent' else None\n",
    "    neg_corr_df = pd.DataFrame(index=columns, columns=columns, dtype='float64') if method_choice != 'percent' else None\n",
    "    overall_corr_df = pd.DataFrame(index=columns, columns=columns, dtype='float64')\n",
    "    \n",
    "    # Binarize the DataFrame\n",
    "    bin_df = df.applymap(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "    \n",
    "    # Iterate over each pair of columns\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            \n",
    "            col1, col2 = columns[i], columns[j]\n",
    "            \n",
    "            # Indices where both columns have the same sign (either both positive or both negative)\n",
    "            same_sign = (bin_df[col1] == bin_df[col2]) & (bin_df[col1] != 0)\n",
    "            \n",
    "            # Indices where both columns are positive, negative, or any\n",
    "            both_pos = (bin_df[col1] == 1) & (bin_df[col2] == 1)\n",
    "            both_neg = (bin_df[col1] == -1) & (bin_df[col2] == -1)\n",
    "            \n",
    "            if method_choice == 'dice':\n",
    "                # Dice Coefficient\n",
    "                pos_value = 2 * both_pos.sum() / (bin_df[col1].eq(1).sum() + bin_df[col2].eq(1).sum())\n",
    "                neg_value = 2 * both_neg.sum() / (bin_df[col1].eq(-1).sum() + bin_df[col2].eq(-1).sum())\n",
    "                \n",
    "            elif method_choice == 'jaccard':\n",
    "                # Jaccard Index\n",
    "                pos_value = both_pos.sum() / ((bin_df[col1] == 1) | (bin_df[col2] == 1)).sum()\n",
    "                neg_value = both_neg.sum() / ((bin_df[col1] == -1) | (bin_df[col2] == -1)).sum()\n",
    "                \n",
    "            elif method_choice == 'percent':\n",
    "                # % Agreement of voxels sharing the same sign\n",
    "                overall_value = same_sign.sum() / len(bin_df)\n",
    "                overall_corr_df.loc[col1, col2] = overall_value\n",
    "                overall_corr_df.loc[col2, col1] = overall_value\n",
    "                continue\n",
    "            \n",
    "            overall_value = (pos_value + neg_value) / 2\n",
    "            \n",
    "            # Update DataFrames\n",
    "            if pos_corr_df is not None:\n",
    "                pos_corr_df.loc[col1, col2] = pos_value\n",
    "                pos_corr_df.loc[col2, col1] = pos_value\n",
    "            if neg_corr_df is not None:\n",
    "                neg_corr_df.loc[col1, col2] = neg_value\n",
    "                neg_corr_df.loc[col2, col1] = neg_value\n",
    "            overall_corr_df.loc[col1, col2] = overall_value\n",
    "            overall_corr_df.loc[col2, col1] = overall_value\n",
    "    \n",
    "    return pos_corr_df, neg_corr_df, overall_corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agreement Methods\n",
    "method  = 'jaccard', 'dice', or 'percent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_corr_df, neg_corr_df, overall_corr_df = compute_agreement(masked_df, 'dice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pos_corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create heatmap of correlation matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(15, 13))\n",
    "sns.heatmap(pos_corr_df, cmap='ocean_hot',square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, vmin=-1, vmax=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(neg_corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create heatmap of correlation matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(15, 13))\n",
    "sns.heatmap(neg_corr_df, cmap='ocean_hot',square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, vmin=-1, vmax=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(overall_corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create heatmap of correlation matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(15, 13))\n",
    "sns.heatmap(overall_corr_df, cmap='ocean_hot',square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, vmin=-1, vmax=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Sub-Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "r, p = spearmanr(masked_df['Memory Network.nii'], masked_df['R-Map.nii'])\n",
    "# Format p-value to display more decimal places\n",
    "formatted_p = \"{:.10f}\".format(p)\n",
    "\n",
    "print(\"Correlation coefficient (r):\", r)\n",
    "print(\"Formatted p-value:\", formatted_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Mantel Test\n",
    "- Struggles on vectors >15 000 length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_1 = 'Cognitive Decline Network.nii'\n",
    "vec_2 = 'R-Map.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skbio.stats.distance import mantel\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Assuming masked_df is your DataFrame and vec_1, vec_2 are column names\n",
    "vector1 = masked_df[vec_1].to_numpy()\n",
    "# vector2 = masked_df[vec_2].to_numpy()\n",
    "\n",
    "# # Convert vectors to distance matrices\n",
    "distance_matrix_1 = squareform(pdist(vector1.reshape(-1, 1), 'euclidean'))\n",
    "# distance_matrix_2 = squareform(pdist(vector2.reshape(-1, 1), 'euclidean'))\n",
    "\n",
    "# # Perform the Mantel test on the distance matrices\n",
    "# correlation, p_value, _ = mantel(distance_matrix_1, distance_matrix_2, method='pearson', permutations=999)\n",
    "\n",
    "# print(\"Correlation:\", correlation)\n",
    "# print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_calvin (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
